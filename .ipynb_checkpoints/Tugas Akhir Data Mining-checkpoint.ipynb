{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "06e7de78",
   "metadata": {},
   "source": [
    "#### Tugas Akhir Data Mining \n",
    "#### \"Mengklasifikasi Data Penipuan Transaksi Menggunakan Kartu Kredit Dengan Metode Naive Bayes, K-NN,  dan Desision Tree\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "238b4c2f",
   "metadata": {},
   "source": [
    "##### Nama : Syaiful Rizal Sidiq\n",
    "##### NIM : A11.2021.13849\n",
    "##### Kelas : A11.4404"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac3f80e5",
   "metadata": {},
   "source": [
    "#### Abstraksi\n",
    "\n",
    "Penipuan dalam transaksi kartu kredit merupakan masalah serius yang perlu ditangani. Masyarakat yang semakin banyak menggunakan kartu kredit membuat tingkat penipuan transaksi kartu kredit semakin meningkat. Experimen ini  menggunakan credit  card  fraud  dataset yang  terdiri  dari 999.999 ribu  data  yang  didapatkan  dari  Kaggle. Melihat itu Metode klasifikasi seperti Naive Bayes, K-NN, dan Decision Tree dapat digunakan untuk mengidentifikasi dan mencegah penipuan tersebut. Naive Bayes menggunakan probabilitas untuk mengklasifikasikan data, K-NN membandingkan transaksi dengan sampel terdekat, dan Decision Tree menggunakan serangkaian keputusan berbasis fitur. Tujuan hasil dari experimen ini yaitu menerapkan ketiga metode tersebut, sehingga perusahaan penerbit kartu kredit dapat membangun model klasifikasi yang akurat, sehingga harapanya dapat melawan penipuan, melindungi pemegang kartu, dan meminimalkan kerugian finansial. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a707f7be",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ba1d4359",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import Library \n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.tree import DecisionTreeClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4f28589e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dan Membaca dataset\n",
    "df = pd.read_csv(\"card_transdata.csv\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6598e68a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>distance_from_home</th>\n",
       "      <th>distance_from_last_transaction</th>\n",
       "      <th>ratio_to_median_purchase_price</th>\n",
       "      <th>repeat_retailer</th>\n",
       "      <th>used_chip</th>\n",
       "      <th>used_pin_number</th>\n",
       "      <th>online_order</th>\n",
       "      <th>fraud</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>57.877857</td>\n",
       "      <td>0.311140</td>\n",
       "      <td>1.945940</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.829943</td>\n",
       "      <td>0.175592</td>\n",
       "      <td>1.294219</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.091079</td>\n",
       "      <td>0.805153</td>\n",
       "      <td>0.427715</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.247564</td>\n",
       "      <td>5.600044</td>\n",
       "      <td>0.362663</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>44.190936</td>\n",
       "      <td>0.566486</td>\n",
       "      <td>2.222767</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5.586408</td>\n",
       "      <td>13.261073</td>\n",
       "      <td>0.064768</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3.724019</td>\n",
       "      <td>0.956838</td>\n",
       "      <td>0.278465</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4.848247</td>\n",
       "      <td>0.320735</td>\n",
       "      <td>1.273050</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.876632</td>\n",
       "      <td>2.503609</td>\n",
       "      <td>1.516999</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>8.839047</td>\n",
       "      <td>2.970512</td>\n",
       "      <td>2.361683</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>14.263530</td>\n",
       "      <td>0.158758</td>\n",
       "      <td>1.136102</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>13.592368</td>\n",
       "      <td>0.240540</td>\n",
       "      <td>1.370330</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>765.282559</td>\n",
       "      <td>0.371562</td>\n",
       "      <td>0.551245</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2.131956</td>\n",
       "      <td>56.372401</td>\n",
       "      <td>6.358667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>13.955972</td>\n",
       "      <td>0.271522</td>\n",
       "      <td>2.798901</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    distance_from_home  distance_from_last_transaction  \\\n",
       "0            57.877857                        0.311140   \n",
       "1            10.829943                        0.175592   \n",
       "2             5.091079                        0.805153   \n",
       "3             2.247564                        5.600044   \n",
       "4            44.190936                        0.566486   \n",
       "5             5.586408                       13.261073   \n",
       "6             3.724019                        0.956838   \n",
       "7             4.848247                        0.320735   \n",
       "8             0.876632                        2.503609   \n",
       "9             8.839047                        2.970512   \n",
       "10           14.263530                        0.158758   \n",
       "11           13.592368                        0.240540   \n",
       "12          765.282559                        0.371562   \n",
       "13            2.131956                       56.372401   \n",
       "14           13.955972                        0.271522   \n",
       "\n",
       "    ratio_to_median_purchase_price  repeat_retailer  used_chip  \\\n",
       "0                         1.945940              1.0        1.0   \n",
       "1                         1.294219              1.0        0.0   \n",
       "2                         0.427715              1.0        0.0   \n",
       "3                         0.362663              1.0        1.0   \n",
       "4                         2.222767              1.0        1.0   \n",
       "5                         0.064768              1.0        0.0   \n",
       "6                         0.278465              1.0        0.0   \n",
       "7                         1.273050              1.0        0.0   \n",
       "8                         1.516999              0.0        0.0   \n",
       "9                         2.361683              1.0        0.0   \n",
       "10                        1.136102              1.0        1.0   \n",
       "11                        1.370330              1.0        1.0   \n",
       "12                        0.551245              1.0        1.0   \n",
       "13                        6.358667              1.0        0.0   \n",
       "14                        2.798901              1.0        0.0   \n",
       "\n",
       "    used_pin_number  online_order  fraud  \n",
       "0               0.0           0.0    0.0  \n",
       "1               0.0           0.0    0.0  \n",
       "2               0.0           1.0    0.0  \n",
       "3               0.0           1.0    0.0  \n",
       "4               0.0           1.0    0.0  \n",
       "5               0.0           0.0    0.0  \n",
       "6               0.0           1.0    0.0  \n",
       "7               1.0           0.0    0.0  \n",
       "8               0.0           0.0    0.0  \n",
       "9               0.0           1.0    0.0  \n",
       "10              0.0           1.0    0.0  \n",
       "11              0.0           1.0    0.0  \n",
       "12              0.0           0.0    0.0  \n",
       "13              0.0           1.0    1.0  \n",
       "14              0.0           1.0    0.0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Menampilkan dataset 5 teratas\n",
    "df.head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "660065d8",
   "metadata": {},
   "source": [
    "### Data Preparation\n",
    "\n",
    "Data  preparation merupakan  proses  untuk  memperbaiki  permasalahan  yang  terdapat dalam  data dengan  mengolah  data dari credit  card  fraud dataset sebanyak  999.999  dengan  8  atribut.  Proses  ini dilakukan  untuk  membuat  data  lebih  baik  dan  lebih  layak  sebelum  diolah  dengan  algoritma.  Pada tahapan ini juga meliputi beberapa proses diantaranya:\n",
    "\n",
    "•Pemilihan  data: Proses ini dilakukan dengan  cara menyeleksi  beberapa  atribut  yang  akan digunakan  sebagai  pemodelan. Atribut  yang  digunakan  yaitu  atribut  V1 sampai V28  dan class. Atribut class yang bernilai 0 jumlah data akan disamakan dengan jumlah data yang bernilai 1.\n",
    "\n",
    "•Pembersihan data: Data awalnya sejumlah 999.999 record di cek apakah masih ada missing value. Apabila ada maka perlu dilakukan   proses cleansing yaitu   apabila   ada missing   value,   maka   data missing   value akan dihilangkan, sehingga mengurangi jumlah data awal.\n",
    "\n",
    "•Transformasi data: Tahapan  ini  menyederhanakan  atribut  pada  data  sehingga  menghasilkan atribut yang baru.\n",
    "\n",
    "Deployment: Proses ini  melakukan dengan  cara  menyajikan  hasil  penelitian melalui GUI dan  memberikan rekomendasi  atau  menggabungkan  suatu  keputusan  dalam  sistem  terhadap objek penelitian agar dapat memberikan saran perbaikan untuk masa yang akan datang."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d9048fa",
   "metadata": {},
   "source": [
    "#### Mengecek apakah ada atribut yang missing value\n",
    "\n",
    "Proses mengecek data pada setiap atribut yang memiliki missing value kemudian menjumlahkannya"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8b84a26a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "distance_from_home                0\n",
       "distance_from_last_transaction    0\n",
       "ratio_to_median_purchase_price    0\n",
       "repeat_retailer                   0\n",
       "used_chip                         0\n",
       "used_pin_number                   0\n",
       "online_order                      0\n",
       "fraud                             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60d89e4f",
   "metadata": {},
   "source": [
    "Dari pengecekan diatas tidak terdapat atribut yang memiliki missing value, maka proses pembersihan data selesai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71063a1f",
   "metadata": {},
   "source": [
    "### Memisahkan fitur dan label\n",
    "\n",
    "Dalam proses pemisahan fitur dan label tujuannya adalah untuk mengidentifikasi atribut-atribut yang relevan dan signifikan dalam mempengaruhi nilai target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d605a438",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(\"fraud\", axis=1)\n",
    "y = df[\"fraud\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e80a97cb",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        distance_from_home  distance_from_last_transaction  \\\n",
      "0                57.877857                        0.311140   \n",
      "1                10.829943                        0.175592   \n",
      "2                 5.091079                        0.805153   \n",
      "3                 2.247564                        5.600044   \n",
      "4                44.190936                        0.566486   \n",
      "...                    ...                             ...   \n",
      "999995            2.207101                        0.112651   \n",
      "999996           19.872726                        2.683904   \n",
      "999997            2.914857                        1.472687   \n",
      "999998            4.258729                        0.242023   \n",
      "999999           58.108125                        0.318110   \n",
      "\n",
      "        ratio_to_median_purchase_price  repeat_retailer  used_chip  \\\n",
      "0                             1.945940              1.0        1.0   \n",
      "1                             1.294219              1.0        0.0   \n",
      "2                             0.427715              1.0        0.0   \n",
      "3                             0.362663              1.0        1.0   \n",
      "4                             2.222767              1.0        1.0   \n",
      "...                                ...              ...        ...   \n",
      "999995                        1.626798              1.0        1.0   \n",
      "999996                        2.778303              1.0        1.0   \n",
      "999997                        0.218075              1.0        1.0   \n",
      "999998                        0.475822              1.0        0.0   \n",
      "999999                        0.386920              1.0        1.0   \n",
      "\n",
      "        used_pin_number  online_order  \n",
      "0                   0.0           0.0  \n",
      "1                   0.0           0.0  \n",
      "2                   0.0           1.0  \n",
      "3                   0.0           1.0  \n",
      "4                   0.0           1.0  \n",
      "...                 ...           ...  \n",
      "999995              0.0           0.0  \n",
      "999996              0.0           0.0  \n",
      "999997              0.0           1.0  \n",
      "999998              0.0           1.0  \n",
      "999999              0.0           1.0  \n",
      "\n",
      "[1000000 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "print(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cfba3f7",
   "metadata": {},
   "source": [
    "#### Filter data\n",
    "\n",
    "Memfilter data yang termasuk kedalam transaksi penipuan atau tidak "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "182c0bbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(912597, 8)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#filter data hanya untuk yang tidak terkena penipuan = 0\n",
    "df[df[\"fraud\"]==0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0cff2a4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(87403, 8)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#filter data hanya untuk yang terkena penipuan =1\n",
    "df[df[\"fraud\"]==1].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b912e13b",
   "metadata": {},
   "source": [
    "setelah dilakukakan filerisasi pada label terdapat  912.597 data yang tidak terkenan penipuan dan 87.403 data yang terkena penipuan.\n",
    "\n",
    "karena datanya tidak seimbang antara yang terkena penipuan dan yang tidak terkenan penipuan maka dilakukan undersampling mengatasi masalah bias yang mungkin timbul akibat perbedaan jumlah sampel dalam setiap kelas. Undersampling melibatkan pengurangan sampel dari kelas mayoritas sehingga jumlah sampel dalam setiap kelas menjadi lebih seimbang. Ini dapat dilakukan dengan cara menghapus sebagian sampel dari kelas mayoritas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a34ae0a",
   "metadata": {},
   "source": [
    "### Mengklasifikasi menggunakan dengan Naive Bayes\n",
    "\n",
    "Experimen klasifikasi menggunakan algoritma Naive Bayes Gaussian. Experimen membantu dalam melatih model, melakukan prediksi, dan mengevaluasi performa model dengan menggunakan metrik evaluasi seperti akurasi, presisi, recall, dan f1-score. Pada Klasifikasi ini saya lakukan 3 kali percobaan dengan menggunakan data testing (data uji)  sebesar 20%, 30%, dan 40%\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ffb3138c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.985335\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      0.99    182557\n",
      "         1.0       0.95      0.88      0.91     17443\n",
      "\n",
      "    accuracy                           0.99    200000\n",
      "   macro avg       0.97      0.94      0.95    200000\n",
      "weighted avg       0.99      0.99      0.99    200000\n",
      "\n",
      "Confusion Matrix:\n",
      " [[181683    874]\n",
      " [  2059  15384]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# Membagi dataset menjadi data latih dan data uji\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Membuat objek klasifikasi K-Nearest Neighbors\n",
    "model_KNN = KNeighborsClassifier(n_neighbors=2)\n",
    "\n",
    "# Melatih model dengan data latih\n",
    "model_KNN.fit(X_train, y_train)\n",
    "\n",
    "# Memprediksi label untuk data uji\n",
    "y_pred = model_KNN.predict(X_test)\n",
    "\n",
    "# Evaluasi model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "report = classification_report(y_test, y_pred)\n",
    "confusion_mat = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Classification Report:\\n\", report)\n",
    "print(\"Confusion Matrix:\\n\", confusion_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ba4083e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import NearMiss\n",
    "\n",
    "\n",
    "# Membagi dataset menjadi data latih dan data uji\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Membuat objek klasifikasi Naive Bayes\n",
    "nb_classifier = GaussianNB()\n",
    "\n",
    "# Melatih model dengan data latih yang telah diundersample\n",
    "nb_classifier.fit(X_train_undersampled, y_train_undersampled)\n",
    "\n",
    "# Mengaplikasikan undersampling menggunakan NearMiss\n",
    "undersampler = NearMiss()\n",
    "X_train_undersampled, y_train_undersampled = undersampler.fit_resample(X_train, y_train)\n",
    "\n",
    "# Memprediksi label untuk data uji\n",
    "y_pred = nb_classifier.predict(X_test)\n",
    "\n",
    "# Evaluasi model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "report = classification_report(y_test, y_pred)\n",
    "confusion_mat = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Classification Report:\\n\", report)\n",
    "print(\"Confusion Matrix:\\n\", confusion_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca0f618a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import NearMiss\n",
    "\n",
    "# Membagi dataset menjadi data latih dan data uji\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=42)\n",
    "\n",
    "# Membuat objek klasifikasi Naive Bayes\n",
    "nb_classifier = GaussianNB()\n",
    "\n",
    "# Melatih model dengan data latih yang telah diundersample\n",
    "nb_classifier.fit(X_train_undersampled, y_train_undersampled)\n",
    "\n",
    "# Mengaplikasikan undersampling menggunakan NearMiss\n",
    "undersampler = NearMiss()\n",
    "X_train_undersampled, y_train_undersampled = undersampler.fit_resample(X_train, y_train)\n",
    "\n",
    "# Memprediksi label untuk data uji\n",
    "y_pred = nb_classifier.predict(X_test)\n",
    "\n",
    "# Evaluasi model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "report = classification_report(y_test, y_pred)\n",
    "confusion_mat = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Classification Report:\\n\", report)\n",
    "print(\"Confusion Matrix:\\n\", confusion_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e8c396e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Membagi dataset menjadi data latih dan data uji\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Membuat objek klasifikasi Decision Tree\n",
    "dt_classifier = DecisionTreeClassifier()\n",
    "\n",
    "# Melatih model dengan data latih\n",
    "dt_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Memprediksi label untuk data uji\n",
    "y_pred = dt_classifier.predict(X_test)\n",
    "\n",
    "# Evaluasi model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "report = classification_report(y_test, y_pred)\n",
    "confusion_mat = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Classification Report:\\n\", report)\n",
    "print(\"Confusion Matrix:\\n\", confusion_mat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "904e9a5f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# Membagi dataset menjadi data latih dan data uji\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Membuat objek klasifikasi K-Nearest Neighbors\n",
    "model_KNN = KNeighborsClassifier(n_neighbors=2)\n",
    "\n",
    "# Melatih model dengan data latih\n",
    "model_KNN.fit(X_train, y_train)\n",
    "\n",
    "# Memprediksi label untuk data uji\n",
    "y_pred = model_KNN.predict(X_test)\n",
    "\n",
    "# Evaluasi model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "report = classification_report(y_test, y_pred)\n",
    "confusion_mat = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Classification Report:\\n\", report)\n",
    "print(\"Confusion Matrix:\\n\", confusion_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "757b8d70",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install imbalanced-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a80006cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from imblearn.under_sampling import NearMiss\n",
    "\n",
    "# Membagi dataset menjadi data latih dan data uji\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Mengaplikasikan undersampling menggunakan NearMiss\n",
    "undersampler = NearMiss()\n",
    "X_train_undersampled, y_train_undersampled = undersampler.fit_resample(X_train, y_train)\n",
    "\n",
    "# Membuat objek klasifikasi K-Nearest Neighbors\n",
    "model_KNN = KNeighborsClassifier(n_neighbors=3)\n",
    "\n",
    "# Melatih model dengan data latih yang telah diundersample\n",
    "model_KNN.fit(X_train_undersampled, y_train_undersampled)\n",
    "\n",
    "# Memprediksi label untuk data uji\n",
    "y_pred = model_KNN.predict(X_test)\n",
    "\n",
    "# Evaluasi model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "report = classification_report(y_test, y_pred)\n",
    "confusion_mat = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Classification Report:\\n\", report)\n",
    "print(\"Confusion Matrix:\\n\", confusion_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8a8cdeb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9781825\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.98      0.99    365248\n",
      "         1.0       0.81      0.98      0.89     34752\n",
      "\n",
      "    accuracy                           0.98    400000\n",
      "   macro avg       0.90      0.98      0.94    400000\n",
      "weighted avg       0.98      0.98      0.98    400000\n",
      "\n",
      "Confusion Matrix:\n",
      " [[357246   8002]\n",
      " [   725  34027]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Membagi dataset menjadi data latih dan data uji\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Mengaplikasikan oversampling menggunakan SMOTE\n",
    "oversampler = SMOTE()\n",
    "X_train_oversampled, y_train_oversampled = oversampler.fit_resample(X_train, y_train)\n",
    "\n",
    "# Membuat objek klasifikasi K-Nearest Neighbors\n",
    "model_KNN = KNeighborsClassifier(n_neighbors=3)\n",
    "\n",
    "# Melatih model dengan data latih yang telah dioversample\n",
    "model_KNN.fit(X_train_oversampled, y_train_oversampled)\n",
    "\n",
    "# Memprediksi label untuk data uji\n",
    "y_pred = model_KNN.predict(X_test)\n",
    "\n",
    "# Evaluasi model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "report = classification_report(y_test, y_pred)\n",
    "confusion_mat = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Classification Report:\\n\", report)\n",
    "print(\"Confusion Matrix:\\n\", confusion_mat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de472d35",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88168406",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33e00cde",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
